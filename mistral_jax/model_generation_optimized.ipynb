{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4313c140-421d-4f1f-a283-3461b8db70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "from functools import partial\n",
    "from equinox._misc import default_floating_dtype\n",
    "from jaxtyping import Array, Float, Scalar\n",
    "from typing import Optional, Tuple, List, NamedTuple\n",
    "\n",
    "from sentencepiece import SentencePieceProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27c428-fd21-41a1-9a5c-99a966f5a2a3",
   "metadata": {},
   "source": [
    "# 1. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd26d27d-8e7e-46e9-ba8d-187a8a57a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self._model = SentencePieceProcessor(model_file=model_path)\n",
    "\n",
    "    @property\n",
    "    def eos_id(self) -> int:\n",
    "        return self._model.eos_id()\n",
    "\n",
    "    @property\n",
    "    def pad_id(self) -> int:\n",
    "        return self._model.pad_id()\n",
    "\n",
    "    def encode(self, s: str) -> List[int]:\n",
    "        return [self._model.bos_id(), *self._model.encode(s)]\n",
    "\n",
    "    def decode(self, t: List[int]) -> str:\n",
    "        return self._model.decode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5aced-2da9-42df-900d-b9d11d5f45fa",
   "metadata": {},
   "source": [
    "# 2. RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431e5fa1-25dd-401a-abfb-1371f5f1b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_frequencies(dim, max_pos, theta=10000.0):\n",
    "    inv_freq = 1.0 / (\n",
    "        theta ** (jnp.arange(0, dim, 2, dtype=jnp.float32)[: (dim // 2)] / dim)\n",
    "    )\n",
    "    t = jnp.arange(0, max_pos, dtype=jnp.float32)\n",
    "    freqs = jnp.outer(t, inv_freq)\n",
    "    return jnp.cos(freqs), jnp.sin(freqs)\n",
    "\n",
    "def calculate_rope(x, cos_freq, sin_freq):\n",
    "    # x shape  is [seqlen, num_heads, heads_dim]\n",
    "    sin = jax.lax.expand_dims(sin_freq, (1,))\n",
    "    cos = jax.lax.expand_dims(cos_freq, (1,))\n",
    "\n",
    "    # Get the even-odd positions from the inputs\n",
    "    x1 = x[..., 0::2]\n",
    "    x2 = x[..., 1::2]\n",
    "\n",
    "    # Matmul with the rotation matrix\n",
    "    # [cos_nθ, -sin_nθ] [x1]\n",
    "    # [sin_nθ,  cos_nθ] [x2]\n",
    "    # => [x1 * cos_nθ - x2 * sin_nθ, x1 * sin_nθ + x2 * cos_nθ]\n",
    "    pos_embed = jnp.stack([x1 * cos - x2 * sin, x1 * sin + x2 * cos], axis=-1)\n",
    "    pos_embed = jax.lax.collapse(pos_embed, -2)\n",
    "    return pos_embed.astype(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1aa31-614e-4483-8599-c5f0b4623292",
   "metadata": {},
   "source": [
    "# 3. RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180fbb2d-ce6f-4b1a-a198-e4f37fab93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(eqx.Module):\n",
    "    eps: float\n",
    "    weight: Float[Array, \"*shape\"]\n",
    "\n",
    "    def __init__(self, dim, eps, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        self.eps = eps\n",
    "        self.weight = jnp.ones(shape=dim, dtype=dtype)\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * jax.lax.rsqrt(jnp.mean(x **2 , keepdims=True) + self.eps)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = self._norm(x.astype(jnp.float32)).astype(x.dtype)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f9a21-bb3c-45e8-805c-5f8605f72423",
   "metadata": {},
   "source": [
    "# 4. FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efffa74f-556b-4c3e-9f73-e23acfa1da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(eqx.Module):\n",
    "    w1: eqx.nn.Linear\n",
    "    w2: eqx.nn.Linear\n",
    "    w3: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "        self.w1 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.w2 = eqx.nn.Linear(args.hidden_dim, args.dim, use_bias=False, key=key2, dtype=dtype)\n",
    "        self.w3 = eqx.nn.Linear(args.dim, args.hidden_dim, use_bias=False, key=key3, dtype=dtype)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = jax.nn.silu(self.w1(x).astype(jnp.float32)).astype(x.dtype)\n",
    "        return self.w2(h * self.w3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c459d5-b30d-48e5-924b-ea661542e8a2",
   "metadata": {},
   "source": [
    "# 5. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2048b724-3015-43c8-be5e-0214eb83af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    head_dim: int\n",
    "    n_kv_heads: int\n",
    "    kv_repeats: int\n",
    "    sliding_window: int\n",
    "    scale: float\n",
    "    split_sizes: Tuple\n",
    "    wqkv: eqx.nn.Linear\n",
    "    wo: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        dtype = default_floating_dtype if dtype is None else dtype\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.head_dim\n",
    "        self.n_kv_heads = args.n_kv_heads\n",
    "        self.dim = args.dim\n",
    "        self.kv_repeats = self.n_heads // self.n_kv_heads\n",
    "        self.sliding_window = args.sliding_window\n",
    "        self.scale = args.head_dim**-0.5\n",
    "        total_head_dim = (args.n_heads + 2 * args.n_kv_heads) * args.head_dim\n",
    "        self.split_sizes = (args.n_heads * args.head_dim, (args.n_heads * args.head_dim) + (args.n_kv_heads * args.head_dim))\n",
    "        self.wqkv = eqx.nn.Linear(args.dim, total_head_dim, use_bias=False, key=key1, dtype=dtype)\n",
    "        self.wo = eqx.nn.Linear(args.n_heads * args.head_dim, args.dim, use_bias=False, key=key2, dtype=dtype)\n",
    "\n",
    "    def compute_scores_and_output(self, xq, key, value, mask, seqlen, pos_mask):\n",
    "        query = jnp.transpose(xq, (1, 0, 2))\n",
    "        key = jnp.transpose(key, (1, 0, 2))\n",
    "        value = jnp.transpose(value, (1, 0, 2))\n",
    "\n",
    "        # # # scores : [n_heads, seqlen | 1, seqlen]\n",
    "        scores = jnp.matmul(query, jnp.transpose(key, (0, 2, 1))) * self.scale\n",
    "        if pos_mask is not None:\n",
    "            scores = jnp.where(pos_mask, -jnp.inf, scores)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Mask will of shape [seqlen, seqlen] but our scores\n",
    "            # have shape [num_heads, seqlen, seqlen], hence we need\n",
    "            # to introduce another dimension in the mask\n",
    "            mask = mask[jnp.newaxis, ...]\n",
    "            scores = scores + mask\n",
    "\n",
    "        scores = jax.nn.softmax(scores.astype(jnp.float32), axis=-1).astype(query.dtype)\n",
    "        output = jnp.matmul(scores, value)\n",
    "        output = jnp.reshape(jnp.transpose(output, (1, 0, 2)), (seqlen, -1))\n",
    "        output = jax.vmap(self.wo)(output)\n",
    "        return output\n",
    "\n",
    "    def __call__(self,  x, cos_freq, sin_freq, positions, mask=None, cache_k=None, cache_v=None):\n",
    "        # x shape: [seqlen, embed_dim]\n",
    "        seqlen = x.shape[0]\n",
    "\n",
    "        xqkv = jax.vmap(self.wqkv)(x)\n",
    "        xq, xk, xv = jnp.split(xqkv, self.split_sizes, axis=-1)\n",
    "\n",
    "        xq = jnp.reshape(xq, (seqlen, self.n_heads, self.head_dim))\n",
    "        xk = jnp.reshape(xk, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "        xv = jnp.reshape(xv, (seqlen, self.n_kv_heads, self.head_dim))\n",
    "\n",
    "        xq = calculate_rope(xq, cos_freq, sin_freq)\n",
    "        xk = calculate_rope(xk, cos_freq, sin_freq)\n",
    "\n",
    "        if positions.shape[0] > 1:\n",
    "            # prefill\n",
    "            cache_k = cache_k.at[positions, :, :].set(xk[positions, :, :], mode=\"drop\")\n",
    "            cache_v = cache_v.at[positions, :, :].set(xv[positions, :, :], mode=\"drop\")\n",
    "            key = jnp.repeat(xk, self.kv_repeats, axis=1)\n",
    "            value = jnp.repeat(xv, self.kv_repeats, axis=1)\n",
    "            output = self.compute_scores_and_output(xq, key, value, mask, seqlen, None)\n",
    "        else:\n",
    "            # single-token generation\n",
    "            one_hot_indices = jax.nn.one_hot(positions, self.sliding_window, dtype=cache_k.dtype).reshape(self.sliding_window, 1, 1)\n",
    "            # the `where` update is only necessary if you are calling the cache multiple times with the same prompt\n",
    "            # Ideally, we expect that you flush out the cache with the new prompt, and start over.\n",
    "            # What does this do? It ensures that we are not adding any values updated earlier \n",
    "            # with the new updates, meaning we are always replacing the value not updating it.\n",
    "            # For example, if prompt had a length of 6, and you want to generate 7th token, this\n",
    "            # ensures that we are not adding the old value of 7th token to the updated value as\n",
    "            # it would lead to wrong results. \n",
    "            # In case, you are flushing the cache after every prompt, remove the `jnp.where()` condition\n",
    "            # and pass the updates directly to cache_k, and cache_v respectively \n",
    "            # i.e. cache_k = cache_k + xk * one_hot_indices\n",
    "            # and cache_v = cache_v + xv * one_hot_indices\n",
    "            k_updates = cache_k + xk * one_hot_indices\n",
    "            v_updates = cache_v + xv * one_hot_indices\n",
    "            cache_k = jnp.where(cache_k, cache_k, k_updates)\n",
    "            cache_v = jnp.where(cache_v, cache_v, v_updates)\n",
    "        \n",
    "            cur_pos = positions[-1] + 1\n",
    "            causal_mask = jnp.broadcast_to(jnp.arange(self.sliding_window) >= cur_pos,(1, 1, self.sliding_window)).reshape(self.sliding_window,1,1)\n",
    "            key = jnp.repeat(jnp.where(causal_mask, 0, cache_k), axis=1, repeats=self.kv_repeats)\n",
    "            value = jnp.repeat(jnp.where(causal_mask, 0, cache_v), axis=1, repeats=self.kv_repeats)\n",
    "            output = self.compute_scores_and_output(xq, key, value, mask, seqlen, causal_mask.reshape((1, 1, self.sliding_window)))\n",
    "\n",
    "        return output, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a123d-c4b1-44f0-a6cd-5daf67c63adb",
   "metadata": {},
   "source": [
    "# 6. TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84cb56f-1a8f-4c28-9f3e-2c180f5e86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(eqx.Module):\n",
    "    dim: int\n",
    "    n_heads: int\n",
    "    attention: Attention\n",
    "    attention_norm: RMSNorm\n",
    "    feed_forward: FeedForward\n",
    "    ffn_norm: RMSNorm\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "\n",
    "        self.attention = Attention(args, key=key1, dtype=dtype)\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "        self.feed_forward = FeedForward(args, key=key2, dtype=dtype)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "        normed_x = jax.vmap(self.attention_norm)(x)\n",
    "        r, cache_k, cache_v = self.attention(normed_x, cos_freq, sin_freq, positions, mask, cache_k, cache_v)\n",
    "        h = x + r\n",
    "        r = jax.vmap(self.feed_forward)(jax.vmap(self.ffn_norm)(h))\n",
    "        out = h +r\n",
    "        return out, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f9502-010b-42ca-86ac-666e9476ff5c",
   "metadata": {},
   "source": [
    "# 7. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdec9a64-57c4-4fb5-8e8a-c3ecb4e5bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(eqx.Module):\n",
    "    tok_embeddings: eqx.nn.Embedding\n",
    "    layers: TransformerBlock\n",
    "    norm: RMSNorm\n",
    "    output: eqx.nn.Linear\n",
    "    vocab_size: int\n",
    "    n_layers: int\n",
    "    sliding_window: int\n",
    "\n",
    "    def __init__(self, args, key, dtype=jnp.bfloat16):\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.sliding_window = args.sliding_window\n",
    "        keys = jax.random.split(key, args.n_layers + 2)\n",
    "        embed_key, linear_key, tf_layers_keys = keys[0], keys[1], keys[2:]\n",
    "\n",
    "        self.tok_embeddings = eqx.nn.Embedding(args.vocab_size, args.dim, key=embed_key, dtype=dtype)\n",
    "        self.norm = RMSNorm(dim=args.dim, eps=args.norm_eps, dtype=dtype)\n",
    "        self.output = eqx.nn.Linear(args.dim, args.vocab_size, use_bias=False, key=linear_key, dtype=dtype)\n",
    "        make_layers = lambda k: TransformerBlock(args, key=k, dtype=dtype)\n",
    "        self.layers = eqx.filter_vmap(make_layers)(tf_layers_keys)\n",
    "        del make_layers\n",
    "\n",
    "    def compute_mask(self, seqlen):\n",
    "        t = jnp.full((seqlen, seqlen), dtype=jnp.bfloat16, fill_value=1)\n",
    "        mask = jnp.tril(t, k=0)\n",
    "        # make the mask banded to account for sliding window\n",
    "        mask = jnp.log(jnp.triu(mask, k=-self.sliding_window))\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def __call__(self, x, cos_freq, sin_freq, positions, mask, cache_k, cache_v):\n",
    "        # x is of shape (seqlen, )\n",
    "        h = jax.vmap(self.tok_embeddings)(x)\n",
    "        \n",
    "        if x.shape[-1] > 1:\n",
    "            seqlen = x.shape[-1]\n",
    "            mask = self.compute_mask(seqlen)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        dynamic_layers, static_layers = eqx.partition(self.layers, eqx.is_array)\n",
    "        \n",
    "        def f(_x, _dynamic_l):\n",
    "            layer = eqx.combine(_dynamic_l, static_layers)\n",
    "            h, cache_k, cache_v, layer_idx = _x\n",
    "            h, cache_ki, cache_vi = layer(\n",
    "                h,\n",
    "                cos_freq,\n",
    "                sin_freq,\n",
    "                positions,\n",
    "                mask,\n",
    "                cache_k[layer_idx, ...],\n",
    "                cache_v[layer_idx, ...],\n",
    "            )\n",
    "            cache_k = cache_k.at[layer_idx, :, :, :].set(cache_ki)\n",
    "            cache_v = cache_v.at[layer_idx, :, :, :].set(cache_vi)\n",
    "            return (h, cache_k, cache_v, layer_idx + 1), None\n",
    "\n",
    "        layer_idx = 0\n",
    "        (h, cache_k, cache_v, layer_idx), _ = jax.lax.scan(f, (h, cache_k, cache_v, layer_idx), dynamic_layers)\n",
    "\n",
    "        h = jax.vmap(self.norm)(h)\n",
    "        h = jax.vmap(self.output)(h).astype(jnp.float32)\n",
    "        return h, cache_k, cache_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a7c63f-4be6-4bad-b6f5-b77c77bcc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelArgs(NamedTuple):\n",
    "    dim: int\n",
    "    n_layers: int\n",
    "    n_heads: int\n",
    "    n_kv_heads: int\n",
    "    head_dim: int\n",
    "    hidden_dim: int\n",
    "    vocab_size: int\n",
    "    sliding_window: int\n",
    "    norm_eps: float\n",
    "    max_batch_size: int = 1\n",
    "\n",
    "\n",
    "with open('./mistral-7B-v0.1/params.json', 'r') as f:\n",
    "    args = ModelArgs(**json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67530c78-98a9-4f84-aa4b-af0819b5f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args, key=jax.random.PRNGKey(1), dtype=jnp.bfloat16)\n",
    "model = eqx.tree_deserialise_leaves(\"mistral7B_jax_port_fast.eqx\", model)\n",
    "model = eqx.filter_vmap(eqx.filter_jit(model), in_axes=(0, None, None, None, None, 0, 0))\n",
    "print(\"Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da969f6-eb91-4df5-9976-1db480914a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_k = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "cache_v = jnp.zeros((args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim), dtype=jnp.bfloat16)\n",
    "cos_freq, sin_freq = precompute_frequencies(args.head_dim, 128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001d96e5-f58d-4ea4-b878-92abcfcb85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pos = jnp.array([0, 1, 2, 3, 4], dtype=jnp.int32)\n",
    "fake_inp = jnp.asarray([[1,  832,  349,  265, 1369]], dtype=jnp.int32)\n",
    "fake_mask = None\n",
    "fake_pos_padded = jnp.pad(fake_pos, (0, args.sliding_window - len(fake_pos)), constant_values=-1)\n",
    "\n",
    "# warmup for prefilling\n",
    "_ = model(fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos_padded, fake_mask, cache_k, cache_v)\n",
    "\n",
    "# warmup for generation\n",
    "fake_pos = jnp.array([5], dtype=jnp.int32)\n",
    "fake_inp = jnp.asarray([[1369]], dtype=jnp.int32)\n",
    "fake_mask = None\n",
    "_ = model(fake_inp, cos_freq[fake_pos], sin_freq[fake_pos], fake_pos_padded, fake_mask, cache_k, cache_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c876b9e3-31d9-4b21-9992-8139dfa17cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\"mistral-7B-v0.1/tokenizer.model\")\n",
    "print(\"Tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d449e2a-aa8f-48f1-b2c7-b63dc99f92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompts, model, tokenizer, max_tokens=36):\n",
    "    \"\"\"Generates completion of length `max_tokens` for a list of given prompts.\"\"\"\n",
    "\n",
    "    cache_shape = (args.max_batch_size, args.n_layers, args.sliding_window, args.n_kv_heads, args.head_dim)\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        # 1. Encode the prompt\n",
    "        encoded = tokenizer.encode(prompt)\n",
    "        cur_pos = len(encoded)\n",
    "\n",
    "        # 2. We need to flush the cache with every prompt. \n",
    "        # Need a better way to do this but for now it's okay!\n",
    "        cache_k = jnp.zeros(cache_shape, dtype=jnp.bfloat16)\n",
    "        cache_v = jnp.zeros(cache_shape, dtype=jnp.bfloat16)\n",
    "\n",
    "        # 3. pre-fill\n",
    "        positions = jnp.arange(0, cur_pos)\n",
    "        positions_padded = jnp.pad(positions, (0, args.sliding_window - len(positions)), constant_values=-1)\n",
    "        print(\"Prefilling...\", end=\"   \")\n",
    "        start = time.time()\n",
    "        logits, cache_k, cache_v = model(\n",
    "            jnp.asarray([encoded]),\n",
    "            cos_freq[positions],\n",
    "            sin_freq[positions],\n",
    "            positions_padded,\n",
    "            None,\n",
    "            cache_k,\n",
    "            cache_v\n",
    "        )\n",
    "        print(f\"Time taken : {time.time()- start :.2f} seconds\")\n",
    "        logprobs = jax.nn.log_softmax(logits, axis=-1)\n",
    "        next_token = jnp.argmax(logprobs[:, -1,:], axis=-1)\n",
    "\n",
    "        # 4. Generation\n",
    "        generated = [next_token[0].item()]\n",
    "        print(\"Generating...\", end=\"   \")\n",
    "        overall_start = time.time()\n",
    "        for t in range(max_tokens):\n",
    "            cur_pos+=1\n",
    "            pos = jnp.array([cur_pos])\n",
    "            logits, cache_k, cache_v = logits, cache_k, cache_v = model(\n",
    "                jax.lax.expand_dims(next_token, (1,)),\n",
    "                cos_freq[pos],\n",
    "                sin_freq[pos],\n",
    "                pos,\n",
    "                None,\n",
    "                cache_k,\n",
    "                cache_v\n",
    "            )\n",
    "            logprobs = jax.nn.log_softmax(logits[:, -1, :], axis=-1)\n",
    "            next_token = jnp.argmax(logprobs, axis=-1)\n",
    "            generated.append(next_token[0].item())\n",
    "    \n",
    "        end = time.time()\n",
    "        print(f\"Time taken to generate {max_tokens} tokens: {end- overall_start:.2f} seconds\")\n",
    "        print(\"\\nPrompt     : \", prompt)\n",
    "        print(\"Completion :\", end=\" \")\n",
    "        res = prompt + \" \" + \"\".join(tokenizer.decode(generated))\n",
    "        print(repr(res))\n",
    "        print(\"\\n\", \"=\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9edc768-0b3f-46b0-9444-8e2246d775b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefilling...   Time taken : 0.01 seconds\n",
      "Generating...   Time taken to generate 64 tokens: 1.66 seconds\n",
      "\n",
      "Prompt     :  This is a test\n",
      "Completion : 'This is a test of the emergency broadcast system.\\n\\nThis is only a test.\\n\\nIf this had been an actual emergency, you would have been instructed where to go and what to do.\\n\\nThis is only a test.\\n\\nThis is a test of the emergency broadcast system.\\n\\nThis is only a test'\n",
      "\n",
      " ===========================================================================\n",
      "Prefilling...   Time taken : 0.01 seconds\n",
      "Generating...   Time taken to generate 64 tokens: 1.63 seconds\n",
      "\n",
      "Prompt     :  Hello, I am a language model,\n",
      "Completion : 'Hello, I am a language model, and I am here to help you with your writing. I can provide you with a variety of writing prompts to get your creative juices flowing.\\n\\n## Introduction\\n\\nWriting prompts are a great way to get your creative juices flowing. They can help you come up with new ideas for stories, poems'\n",
      "\n",
      " ===========================================================================\n",
      "Prefilling...   Time taken : 0.01 seconds\n",
      "Generating...   Time taken to generate 64 tokens: 1.63 seconds\n",
      "\n",
      "Prompt     :  I am a helpful assistant\n",
      "Completion : 'I am a helpful assistant to my wife, who is a full-time artist. I am also a part-time artist, and I have been working on a series of paintings that I call “The Art of the Artist.” The series is about the process of creating art, and how it can be both a joy and a struggle.\\n\\n'\n",
      "\n",
      " ===========================================================================\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"This is a test\",\n",
    "    \"Hello, I am a language model,\",\n",
    "    \"I am a helpful assistant\"\n",
    "]\n",
    "generate(prompts, model, tokenizer, max_tokens=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3bcaa-b148-4a64-9908-d50ab91d7f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
